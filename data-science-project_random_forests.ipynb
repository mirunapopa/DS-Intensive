{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import pylab as pl\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn import cross_validation\n",
    "\n",
    "%matplotlib inline\n",
    "plt.style.use('ggplot')\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#defining function to read data \n",
    "def read_training_data(data_files):\n",
    "    \n",
    "    age_gender = pd.read_csv(data_files['age_gender'])\n",
    "    countries = pd.read_csv(data_files['countries'])\n",
    "    sessions = pd.read_csv(data_files['sessions'])\n",
    "    train_users = pd.read_csv(data_files['users'])\n",
    "    \n",
    "    return age_gender, countries, sessions, train_users\n",
    "\n",
    "#def"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data_files = {'age_gender':'data/age_gender_bkts.csv',\n",
    "'countries':'data/countries.csv',\n",
    "'sessions':'data/sessions.csv',\n",
    "'users':'data/train_users_2.csv'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#general data wrangling\n",
    "def clean_up(dataframe):\n",
    "\n",
    "    #dealing with missing data\n",
    "    dataframe.replace(\"-unknown-\", np.nan, inplace = True)\n",
    "    new_timestamp = dataframe.timestamp_first_active.astype(str)\n",
    "    dates = pd.to_datetime(pd.Series([datetime.strptime(date, '%Y%m%d%H%M%S') for date in new_timestamp]))\n",
    "    \n",
    "    # replace age in areas where it doesn't make sense with -1\n",
    "    av = dataframe.age.values\n",
    "    dataframe['age'] = np.where(np.logical_or(av<14, av>100), -1, av)\n",
    "    \n",
    "    #replacing datetime objects which are more difficult to work with\n",
    "    dataframe['timestamp_first_active'] = dates\n",
    "    dataframe['date_account_created'] = pd.to_datetime(dataframe.date_account_created)\n",
    "    dataframe['date_first_booking'] = pd.to_datetime(dataframe.date_first_booking)\n",
    "    dataframe.rename(columns = {'id':'user_id'}, inplace = True)\n",
    "    df = dataframe.merge(sessions, on = 'user_id', how = 'left')\n",
    "    user_ids = df['user_id']\n",
    "    df_2 = df.drop('user_id', axis = 1)\n",
    "    \n",
    "    #sepparating in order to have numerical values for each\n",
    "    \n",
    "    #date_account_created\n",
    "    df_2['dac_year'] = df_2.date_account_created.dt.year\n",
    "    df_2['dac_month'] = df_2.date_account_created.dt.month\n",
    "    df_2['dac_day'] = df_2.date_account_created.dt.day\n",
    "\n",
    "    #timestamp_first_active\n",
    "    df_2['tfa_year'] = df_2.timestamp_first_active.dt.year\n",
    "    df_2['tfa_month'] = df_2.timestamp_first_active.dt.month\n",
    "    df_2['tfa_day'] = df_2.timestamp_first_active.dt.day\n",
    "\n",
    "    #dropping timestamps from model\n",
    "    df_2 = df_2.drop(['date_account_created','timestamp_first_active','date_first_booking'],axis = 1)\n",
    "    \n",
    "    \n",
    "    #condition to check if it's the training set or test set\n",
    "    if 'country_destination' in list(df_2.columns):\n",
    "\n",
    "        labels = df_2.country_destination\n",
    "        df_2 = df_2.drop('country_destination', axis = 1)\n",
    "        \n",
    "        print df_2.shape[0], user_ids.shape[0] \n",
    "        return df_2, labels, user_ids, df_2.columns\n",
    "        \n",
    "    else:\n",
    "        print df_2.shape[0], user_ids.shape[0] \n",
    "        return df_2, user_ids, df_2.columns\n",
    "    \n",
    "    #if\n",
    "\n",
    "#def\n",
    "\n",
    "def encode_df(df_in,feature_list):\n",
    "    \n",
    "    #encoding all the non-numerical variables\n",
    "    \n",
    "    le = preprocessing.LabelEncoder()\n",
    "    \n",
    "    for item in feature_list:\n",
    "        le.fit(df_in[item])\n",
    "        encoded = le.transform(df_in[item])\n",
    "        df_in[item] = encoded\n",
    "    #for\n",
    "    \n",
    "    df_in = df_in.fillna(-1)\n",
    "    \n",
    "    return df_in\n",
    "\n",
    "#def\n",
    "\n",
    "def preprocessing_df(df_in,mode,normalizers=None):\n",
    "    \n",
    "    #\n",
    "    # normalising the rest of the variables\n",
    "    #\n",
    "    \n",
    "    if mode == 'train':\n",
    "        scaler = preprocessing.MinMaxScaler().fit(df_in)\n",
    "        df_in= scaler.transform(df_in)\n",
    "        normalizers = scaler\n",
    "        return df_in, normalizers\n",
    "    elif mode == 'test':\n",
    "        df_in = normalizers.transform(df_in)\n",
    "        return df_in\n",
    "    else:\n",
    "        print 'Mode not defined {}'.format(mode)\n",
    "    #if\n",
    "    \n",
    "#def"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "feature_list = ['gender','signup_method','language','affiliate_channel',\n",
    "         'affiliate_provider','first_affiliate_tracked','affiliate_provider',\n",
    "         'first_affiliate_tracked','signup_app','first_device_type','first_browser','action',\n",
    "        'action_type','action_detail','device_type']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading all the data\n",
    "****"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "age_gender, countries, sessions, train_users = read_training_data(data_files)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing train data\n",
    "****\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5677593 5677593\n"
     ]
    }
   ],
   "source": [
    "train_set, train_labels, train_user_id, column_names_train = clean_up(train_users)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5677593"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set = encode_df(train_set, feature_list)\n",
    "train_set.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_set, normalizers = preprocessing_df(train_set,'train',normalizers=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 1, 0],\n",
       "       ..., \n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_dummies = pd.get_dummies(train_labels)\n",
    "#encoded_dummies = pd.get_dummies(train_labels).as_matrix()\n",
    "from sklearn import preprocessing\n",
    "le = preprocessing.LabelBinarizer()\n",
    "train_labels_set = le.fit_transform(train_labels)\n",
    "train_labels_set\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reducing Dimensionality\n",
    "****"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting the top 15 features from 5677593 rows\n",
      "done in 32.556s\n",
      "Projecting the input data on the eigenvalues orthonormal basis\n",
      "done in 1.967s\n"
     ]
    }
   ],
   "source": [
    "from time import time\n",
    "from sklearn.decomposition import RandomizedPCA\n",
    "n_components = 15\n",
    "\n",
    "print \"Extracting the top %d features from %d rows\" % (n_components, train_set.shape[0])\n",
    "t0 = time()\n",
    "pca = RandomizedPCA(n_components=n_components, whiten=True).fit(train_set)\n",
    "print \"done in %0.3fs\" % (time() - t0)\n",
    "\n",
    "#eigenvalues = pca.components_.reshape((n_components, X_train.shape[0],  X_train.shape[1]))\n",
    "\n",
    "print \"Projecting the input data on the eigenvalues orthonormal basis\"\n",
    "t0 = time()\n",
    "X_train_pca = pca.transform(train_set)\n",
    "#X_test_pca = pca.transform(test_set)\n",
    "print \"done in %0.3fs\" % (time() - t0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitting Training Data - train and CV\n",
    "****"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = cross_validation.train_test_split(X_train_pca, train_labels_set, test_size=0.3, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training: 3974315, 3974315\n",
      "test: 1703278, 1703278\n"
     ]
    }
   ],
   "source": [
    "print \"training: %i, %i\" % (X_train.shape[0],y_train.shape[0])\n",
    "print \"test: %i, %i\" % (X_test.shape[0],y_test.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training phase\n",
    "****"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "clf = OneVsRestClassifier(RandomForestClassifier(n_estimators = 100, random_state=0, n_jobs = -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "t0 = time()\n",
    "clf.fit(X_train, y_train)\n",
    "print \"done in %0.3fs\" % (time() - t0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y_pred = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#plotting importances at each class\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "y = {}\n",
    "for i in range(0,len(clf.estimators_)-1):\n",
    "    importances = clf.estimators_[i].feature_importances_\n",
    "    std = np.std([tree.feature_importances_ for tree in clf.estimators_],\n",
    "                 axis=0)\n",
    "    indices = np.argsort(importances)[::-1]\n",
    "\n",
    "    # Print the feature ranking\n",
    "    print(\"Feature ranking:\")\n",
    "    x = {}\n",
    "    for f in range(X_train.shape[1]):\n",
    "        print(\"%d. feature %d (%f)\" % (f + 1, indices[f], importances[indices[f]]))\n",
    "        x[f+1] = indices[f]\n",
    "\n",
    "    # Plot the feature importances of the forest\n",
    "    plt.figure()\n",
    "    y[i] = x\n",
    "    plt.title(\"Feature importances\")\n",
    "    plt.bar(range(X_train.shape[1]), importances[indices],\n",
    "           color=\"r\", yerr=std[indices], align=\"center\")\n",
    "    plt.xticks(range(X_train.shape[1]), indices)\n",
    "    plt.xlim([-1, X_train.shape[1]])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "print metrics.f1_score(y_test, y_pred)\n",
    "print metrics.accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Process Again\n",
    "****"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print train_users.shape[0], train_set.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading Test Data\n",
    "****"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_users = pd.read_csv('data/test_users.csv')\n",
    "test_set, test_user_id, column_names_test = clean_up(test_users)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_set = encode_df(test_set, feature_list)\n",
    "test_set = preprocessing_df(test_set, 'test', normalizers = normalizers)\n",
    "test_set.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_test_pca = pca.transform(test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_test_pca.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#training on the entire train set\n",
    "t0 = time()\n",
    "clf = OneVsRestClassifier(RandomForestClassifier(bootstrap = False, random_state=0, n_jobs = -1))\n",
    "print \"done in %0.3fs\" % (time() - t0)\n",
    "\n",
    "t0= time()\n",
    "clf.fit(X_train_pca, train_labels_set)\n",
    "print \"done in %0.3fs\" % (time() - t0)\n",
    "\n",
    "t0 = time()\n",
    "#predict probabilities of each country\n",
    "y_pred = clf.predict_proba(X_test_pca)\n",
    "print \"done in %0.3fs\" % (time() - t0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y_pred.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "last_df = pd.concat([test_user_id,pd.DataFrame(y_pred, columns = encoded_dummies.columns)], axis = 1)\n",
    "last_df = last_df.groupby('user_id').mean().reset_index()\n",
    "\n",
    "last_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import operator\n",
    "\n",
    "ids = []\n",
    "result = {}\n",
    "for index, row in last_df.iterrows():\n",
    "    country_values = row[1:].to_dict()\n",
    "    sorted_vals = sorted(country_values.items(), key=operator.itemgetter(1), reverse = True)[:5]\n",
    "    result[row[0]]= sorted_vals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "some_other_df = pd.DataFrame(result).T\n",
    "some_other_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pd.DataFrame(some_other_df.unstack(0))\\\n",
    ".reset_index()\\\n",
    ".sort_values(['level_1','level_0'])[['level_1',0]].to_csv('something.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### This returns a score of 84.53% accuracy on the website"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(clf.estimators_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(__doc__)\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import cross_validation\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.datasets import load_digits\n",
    "from sklearn.learning_curve import learning_curve\n",
    "\n",
    "\n",
    "def plot_learning_curve(estimator, title, X, y, ylim=None, cv=None,\n",
    "                        n_jobs=1, train_sizes=np.linspace(.1, 1.0, 5)):\n",
    "    \"\"\"\n",
    "    Generate a simple plot of the test and traning learning curve.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    estimator : object type that implements the \"fit\" and \"predict\" methods\n",
    "        An object of that type which is cloned for each validation.\n",
    "\n",
    "    title : string\n",
    "        Title for the chart.\n",
    "\n",
    "    X : array-like, shape (n_samples, n_features)\n",
    "        Training vector, where n_samples is the number of samples and\n",
    "        n_features is the number of features.\n",
    "\n",
    "    y : array-like, shape (n_samples) or (n_samples, n_features), optional\n",
    "        Target relative to X for classification or regression;\n",
    "        None for unsupervised learning.\n",
    "\n",
    "    ylim : tuple, shape (ymin, ymax), optional\n",
    "        Defines minimum and maximum yvalues plotted.\n",
    "\n",
    "    cv : integer, cross-validation generator, optional\n",
    "        If an integer is passed, it is the number of folds (defaults to 3).\n",
    "        Specific cross-validation objects can be passed, see\n",
    "        sklearn.cross_validation module for the list of possible objects\n",
    "\n",
    "    n_jobs : integer, optional\n",
    "        Number of jobs to run in parallel (default 1).\n",
    "    \"\"\"\n",
    "    plt.figure()\n",
    "    plt.title(title)\n",
    "    if ylim is not None:\n",
    "        plt.ylim(*ylim)\n",
    "    plt.xlabel(\"Training examples\")\n",
    "    plt.ylabel(\"Score\")\n",
    "    train_sizes, train_scores, test_scores = learning_curve(\n",
    "        estimator, X, y, cv=cv, n_jobs=n_jobs, train_sizes=train_sizes)\n",
    "    train_scores_mean = np.mean(train_scores, axis=1)\n",
    "    train_scores_std = np.std(train_scores, axis=1)\n",
    "    test_scores_mean = np.mean(test_scores, axis=1)\n",
    "    test_scores_std = np.std(test_scores, axis=1)\n",
    "    plt.grid()\n",
    "\n",
    "    plt.fill_between(train_sizes, train_scores_mean - train_scores_std,\n",
    "                     train_scores_mean + train_scores_std, alpha=0.1,\n",
    "                     color=\"r\")\n",
    "    plt.fill_between(train_sizes, test_scores_mean - test_scores_std,\n",
    "                     test_scores_mean + test_scores_std, alpha=0.1, color=\"g\")\n",
    "    plt.plot(train_sizes, train_scores_mean, 'o-', color=\"r\",\n",
    "             label=\"Training score\")\n",
    "    plt.plot(train_sizes, test_scores_mean, 'o-', color=\"g\",\n",
    "             label=\"Cross-validation score\")\n",
    "\n",
    "    plt.legend(loc=\"best\")\n",
    "    return plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "title = \"Learning Curves (Random Forest)\"\n",
    "# Cross validation with 100 iterations to get smoother mean test and train\n",
    "# score curves, each time with 20% data randomly selected as a validation set.\n",
    "cv = cross_validation.ShuffleSplit(train_set.shape[0], n_iter=100,\n",
    "                                   test_size=0.3, random_state=0)\n",
    "\n",
    "estimator = OneVsRestClassifier(RandomForestClassifier(bootstrap = False, random_state=0))\n",
    "plot_learning_curve(estimator, title, train_set, train_labels_set, ylim=(0.7, 1.01), cv=cv, n_jobs=4)\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
