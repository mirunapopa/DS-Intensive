{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "from sklearn import preprocessing\n",
    "from xgboost.sklearn import XGBClassifier\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import pylab as pl\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn import cross_validation\n",
    "\n",
    "%matplotlib inline\n",
    "plt.style.use('ggplot')\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def read_training_data(data_files):\n",
    "    \n",
    "    age_gender = pd.read_csv(data_files['age_gender'])\n",
    "    countries = pd.read_csv(data_files['countries'])\n",
    "    sessions = pd.read_csv(data_files['sessions'])\n",
    "    train_users = pd.read_csv(data_files['users'])\n",
    "    \n",
    "    return age_gender, countries, sessions, train_users\n",
    "\n",
    "#def"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data_files = {'age_gender':'data/age_gender_bkts.csv',\n",
    "'countries':'data/countries.csv',\n",
    "'sessions':'data/sessions.csv',\n",
    "'users':'data/train_users_2.csv'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def clean_up(dataframe):\n",
    "\n",
    "    dataframe.replace(\"-unknown-\", np.nan, inplace = True)\n",
    "    new_timestamp = dataframe.timestamp_first_active.astype(str)\n",
    "    dates = pd.to_datetime(pd.Series([datetime.strptime(date, '%Y%m%d%H%M%S') for date in new_timestamp]))\n",
    "    \n",
    "    #easiness in using datetime objects\n",
    "    dataframe['timestamp_first_active'] = dates\n",
    "    dataframe['date_account_created'] = pd.to_datetime(dataframe.date_account_created)\n",
    "    dataframe['date_first_booking'] = pd.to_datetime(dataframe.date_first_booking)\n",
    "    dataframe.rename(columns = {'id':'user_id'}, inplace = True)\n",
    "    df = dataframe.merge(sessions, on = 'user_id', how = 'left')\n",
    "    user_ids = df['user_id']\n",
    "    df_2 = df.drop('user_id', axis = 1)\n",
    "    \n",
    "    #sepparating in order to have numerical values for each\n",
    "    \n",
    "    #date_account_created\n",
    "    df_2['dac_year'] = df_2.date_account_created.dt.year\n",
    "    df_2['dac_month'] = df_2.date_account_created.dt.month\n",
    "    df_2['dac_day'] = df_2.date_account_created.dt.day\n",
    "\n",
    "    #timestamp_first_active\n",
    "    df_2['tfa_year'] = df_2.timestamp_first_active.dt.year\n",
    "    df_2['tfa_month'] = df_2.timestamp_first_active.dt.month\n",
    "    df_2['tfa_day'] = df_2.timestamp_first_active.dt.day\n",
    "\n",
    "    #date_first_booking\n",
    "#     df_2['dfb_year'] = df_2.date_first_booking.dt.year\n",
    "#     df_2['dfb_month'] = df_2.date_first_booking.dt.month\n",
    "#     df_2['dfb_day'] = df_2.date_first_booking.dt.day\n",
    "    df_2 = df_2.drop(['date_account_created','timestamp_first_active','date_first_booking'],axis = 1)\n",
    "    \n",
    "    if 'country_destination' in list(df_2.columns):\n",
    "\n",
    "        labels = df_2.country_destination\n",
    "        df_2 = df_2.drop('country_destination', axis = 1)\n",
    "        \n",
    "        print df_2.shape[0], user_ids.shape[0] \n",
    "        return df_2, labels, user_ids\n",
    "        \n",
    "    else:\n",
    "        print df_2.shape[0], user_ids.shape[0] \n",
    "        return df_2, user_ids\n",
    "    \n",
    "    #if\n",
    "\n",
    "#def\n",
    "\n",
    "def encode_df(df_in,feature_list):\n",
    "    \n",
    "    #encoding all the non-numerical variables\n",
    "    \n",
    "    le = preprocessing.LabelEncoder()\n",
    "    \n",
    "    for item in feature_list:\n",
    "        le.fit(df_in[item])\n",
    "        encoded = le.transform(df_in[item])\n",
    "        df_in[item] = encoded\n",
    "    #for\n",
    "    \n",
    "    df_in = df_in.fillna(-1)\n",
    "    \n",
    "    return df_in\n",
    "\n",
    "#def\n",
    "\n",
    "def preprocessing_df(df_in,mode,normalizers=None):\n",
    "    \n",
    "    #\n",
    "    # normalising the rest of the variables\n",
    "    #\n",
    "    \n",
    "    if mode == 'train':\n",
    "        scaler = preprocessing.MinMaxScaler().fit(df_in)\n",
    "        df_in= scaler.transform(df_in)\n",
    "        normalizers = scaler\n",
    "        return df_in, normalizers\n",
    "    elif mode == 'test':\n",
    "        df_in = normalizers.transform(df_in)\n",
    "        return df_in\n",
    "    else:\n",
    "        print 'Mode not defined {}'.format(mode)\n",
    "    #if\n",
    "    \n",
    "#def"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "feature_list = ['gender','signup_method','language','affiliate_channel',\n",
    "         'affiliate_provider','first_affiliate_tracked','affiliate_provider',\n",
    "         'first_affiliate_tracked','signup_app','first_device_type','first_browser','action',\n",
    "        'action_type','action_detail','device_type']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading all the data\n",
    "****"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "age_gender, countries, sessions, train_users = read_training_data(data_files)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing train data\n",
    "****\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5677593 5677593\n"
     ]
    }
   ],
   "source": [
    "train_set, train_labels, train_user_id = clean_up(train_users)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5677593"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set = encode_df(train_set, feature_list)\n",
    "train_set.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_set, normalizers = preprocessing_df(train_set,'train',normalizers=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 7,  7, 10, ...,  7,  7,  7])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_dummies = pd.get_dummies(train_labels)\n",
    "#encoded_dummies = pd.get_dummies(train_labels).as_matrix()\n",
    "from sklearn import preprocessing\n",
    "le = preprocessing.LabelEncoder()\n",
    "train_labels_set = le.fit_transform(train_labels)\n",
    "train_labels_set\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitting Training Data - train and CV\n",
    "****"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = cross_validation.train_test_split(train_set, train_labels_set, test_size=0.3, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training: 3974315, 3974315\n",
      "test: 1703278, 1703278\n"
     ]
    }
   ],
   "source": [
    "print \"training: %i, %i\" % (X_train.shape[0],y_train.shape[0])\n",
    "print \"test: %i, %i\" % (X_test.shape[0],y_test.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training phase\n",
    "****"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "xgb = XGBClassifier(max_depth=6, learning_rate=0.3, n_estimators=25,\n",
    "                    objective='multi:softprob', subsample=0.5, colsample_bytree=0.5, seed=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "xgb.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y_pred = xgb.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "xgb.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "clf.estimator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "print metrics.f1_score(y_test, y_pred)\n",
    "print metrics.accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# submission = DataFrame(columns=[\"id\", \"country\"])\n",
    "\n",
    "# # sort countries according to most probable destination country \n",
    "# for key in country_df['country'].value_counts().index:\n",
    "#     submission = pd.concat([submission, country_df[country_df[\"country\"] == key]], ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Process Again\n",
    "****"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "213451 5677593\n"
     ]
    }
   ],
   "source": [
    "print train_users.shape[0], train_set.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading Test Data\n",
    "****"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4995712 4995712\n"
     ]
    }
   ],
   "source": [
    "test_users = pd.read_csv('data/test_users.csv')\n",
    "test_set, test_user_id = clean_up(test_users)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4995712"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_set = encode_df(test_set, feature_list)\n",
    "test_set = preprocessing_df(test_set, 'test', normalizers = normalizers)\n",
    "test_set.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-0f5dbead491a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m xgb = XGBClassifier(max_depth=6, learning_rate=0.3, n_estimators=25,\n\u001b[1;32m      3\u001b[0m                     objective='multi:softprob', subsample=0.5, colsample_bytree=0.5, seed=0)\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mxgb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_set\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_labels_set\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m#predict probabilities of each country\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/mirunapopa/anaconda/lib/python2.7/site-packages/xgboost/sklearn.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, eval_set, eval_metric, early_stopping_rounds, verbose)\u001b[0m\n\u001b[1;32m    341\u001b[0m                               \u001b[0mearly_stopping_rounds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mearly_stopping_rounds\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    342\u001b[0m                               \u001b[0mevals_result\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mevals_result\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeval\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 343\u001b[0;31m                               verbose_eval=verbose)\n\u001b[0m\u001b[1;32m    344\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    345\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mevals_result\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/mirunapopa/anaconda/lib/python2.7/site-packages/xgboost/training.pyc\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(params, dtrain, num_boost_round, evals, obj, feval, maximize, early_stopping_rounds, evals_result, verbose_eval, learning_rates, xgb_model)\u001b[0m\n\u001b[1;32m    119\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mearly_stopping_rounds\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_boost_round\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 121\u001b[0;31m             \u001b[0mbst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    122\u001b[0m             \u001b[0mnboost\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevals\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/mirunapopa/anaconda/lib/python2.7/site-packages/xgboost/core.pyc\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, dtrain, iteration, fobj)\u001b[0m\n\u001b[1;32m    692\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    693\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mfobj\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 694\u001b[0;31m             \u001b[0m_check_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_LIB\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mXGBoosterUpdateOneIter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miteration\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    695\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    696\u001b[0m             \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtrain\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#training on the entire train set\n",
    "xgb = XGBClassifier(max_depth=6, learning_rate=0.3, n_estimators=25,\n",
    "                    objective='multi:softprob', subsample=0.5, colsample_bytree=0.5, seed=0)\n",
    "xgb.fit(train_set, train_labels_set)\n",
    "\n",
    "#predict probabilities of each country\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y_pred = xgb.predict_proba(test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y_pred.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>AU</th>\n",
       "      <th>CA</th>\n",
       "      <th>DE</th>\n",
       "      <th>ES</th>\n",
       "      <th>FR</th>\n",
       "      <th>GB</th>\n",
       "      <th>IT</th>\n",
       "      <th>NDF</th>\n",
       "      <th>NL</th>\n",
       "      <th>PT</th>\n",
       "      <th>US</th>\n",
       "      <th>other</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0010k6l0om</td>\n",
       "      <td>0.002662</td>\n",
       "      <td>0.003294</td>\n",
       "      <td>0.003383</td>\n",
       "      <td>0.010376</td>\n",
       "      <td>0.142130</td>\n",
       "      <td>0.004775</td>\n",
       "      <td>0.006505</td>\n",
       "      <td>0.660242</td>\n",
       "      <td>0.005481</td>\n",
       "      <td>0.002781</td>\n",
       "      <td>0.126247</td>\n",
       "      <td>0.032122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0031awlkjq</td>\n",
       "      <td>0.001934</td>\n",
       "      <td>0.002873</td>\n",
       "      <td>0.003023</td>\n",
       "      <td>0.015783</td>\n",
       "      <td>0.022399</td>\n",
       "      <td>0.017558</td>\n",
       "      <td>0.024505</td>\n",
       "      <td>0.545665</td>\n",
       "      <td>0.005537</td>\n",
       "      <td>0.002944</td>\n",
       "      <td>0.331988</td>\n",
       "      <td>0.025790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00378ocvlh</td>\n",
       "      <td>0.003487</td>\n",
       "      <td>0.028285</td>\n",
       "      <td>0.006139</td>\n",
       "      <td>0.019800</td>\n",
       "      <td>0.037462</td>\n",
       "      <td>0.012328</td>\n",
       "      <td>0.029445</td>\n",
       "      <td>0.487668</td>\n",
       "      <td>0.007177</td>\n",
       "      <td>0.004101</td>\n",
       "      <td>0.318048</td>\n",
       "      <td>0.046060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0048rkdgb1</td>\n",
       "      <td>0.001330</td>\n",
       "      <td>0.001041</td>\n",
       "      <td>0.001195</td>\n",
       "      <td>0.129885</td>\n",
       "      <td>0.003299</td>\n",
       "      <td>0.001575</td>\n",
       "      <td>0.306820</td>\n",
       "      <td>0.449650</td>\n",
       "      <td>0.001371</td>\n",
       "      <td>0.001294</td>\n",
       "      <td>0.093213</td>\n",
       "      <td>0.009327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0057snrdpu</td>\n",
       "      <td>0.001897</td>\n",
       "      <td>0.002445</td>\n",
       "      <td>0.019717</td>\n",
       "      <td>0.005545</td>\n",
       "      <td>0.008332</td>\n",
       "      <td>0.003514</td>\n",
       "      <td>0.417869</td>\n",
       "      <td>0.364591</td>\n",
       "      <td>0.001758</td>\n",
       "      <td>0.001384</td>\n",
       "      <td>0.135747</td>\n",
       "      <td>0.037200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      user_id        AU        CA        DE        ES        FR        GB  \\\n",
       "0  0010k6l0om  0.002662  0.003294  0.003383  0.010376  0.142130  0.004775   \n",
       "1  0031awlkjq  0.001934  0.002873  0.003023  0.015783  0.022399  0.017558   \n",
       "2  00378ocvlh  0.003487  0.028285  0.006139  0.019800  0.037462  0.012328   \n",
       "3  0048rkdgb1  0.001330  0.001041  0.001195  0.129885  0.003299  0.001575   \n",
       "4  0057snrdpu  0.001897  0.002445  0.019717  0.005545  0.008332  0.003514   \n",
       "\n",
       "         IT       NDF        NL        PT        US     other  \n",
       "0  0.006505  0.660242  0.005481  0.002781  0.126247  0.032122  \n",
       "1  0.024505  0.545665  0.005537  0.002944  0.331988  0.025790  \n",
       "2  0.029445  0.487668  0.007177  0.004101  0.318048  0.046060  \n",
       "3  0.306820  0.449650  0.001371  0.001294  0.093213  0.009327  \n",
       "4  0.417869  0.364591  0.001758  0.001384  0.135747  0.037200  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "last_df = pd.concat([test_user_id,pd.DataFrame(y_pred, columns = encoded_dummies.columns)], axis = 1)\n",
    "last_df = last_df.groupby('user_id').mean().reset_index()\n",
    "\n",
    "last_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import operator\n",
    "\n",
    "ids = []\n",
    "result = {}\n",
    "for index, row in last_df.iterrows():\n",
    "    country_values = row[1:].to_dict()\n",
    "    sorted_vals = sorted(country_values.items(), key=operator.itemgetter(1), reverse = True)[:5]\n",
    "    result[row[0]]= sorted_vals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0010k6l0om</th>\n",
       "      <td>(NDF, 0.660241723061)</td>\n",
       "      <td>(FR, 0.142130047083)</td>\n",
       "      <td>(US, 0.126246646047)</td>\n",
       "      <td>(other, 0.0321221202612)</td>\n",
       "      <td>(ES, 0.0103762643412)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0031awlkjq</th>\n",
       "      <td>(NDF, 0.545664906502)</td>\n",
       "      <td>(US, 0.331988096237)</td>\n",
       "      <td>(other, 0.025790207088)</td>\n",
       "      <td>(IT, 0.0245048329234)</td>\n",
       "      <td>(FR, 0.0223994627595)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>00378ocvlh</th>\n",
       "      <td>(NDF, 0.487668454647)</td>\n",
       "      <td>(US, 0.318047821522)</td>\n",
       "      <td>(other, 0.04605967924)</td>\n",
       "      <td>(FR, 0.0374619215727)</td>\n",
       "      <td>(IT, 0.0294449161738)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0048rkdgb1</th>\n",
       "      <td>(NDF, 0.449649810791)</td>\n",
       "      <td>(IT, 0.306819587946)</td>\n",
       "      <td>(ES, 0.129884615541)</td>\n",
       "      <td>(US, 0.0932128354907)</td>\n",
       "      <td>(other, 0.00932735390961)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0057snrdpu</th>\n",
       "      <td>(IT, 0.417868584394)</td>\n",
       "      <td>(NDF, 0.364591240883)</td>\n",
       "      <td>(US, 0.135746642947)</td>\n",
       "      <td>(other, 0.0371996089816)</td>\n",
       "      <td>(DE, 0.0197173804045)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                0                      1  \\\n",
       "0010k6l0om  (NDF, 0.660241723061)   (FR, 0.142130047083)   \n",
       "0031awlkjq  (NDF, 0.545664906502)   (US, 0.331988096237)   \n",
       "00378ocvlh  (NDF, 0.487668454647)   (US, 0.318047821522)   \n",
       "0048rkdgb1  (NDF, 0.449649810791)   (IT, 0.306819587946)   \n",
       "0057snrdpu   (IT, 0.417868584394)  (NDF, 0.364591240883)   \n",
       "\n",
       "                                  2                         3  \\\n",
       "0010k6l0om     (US, 0.126246646047)  (other, 0.0321221202612)   \n",
       "0031awlkjq  (other, 0.025790207088)     (IT, 0.0245048329234)   \n",
       "00378ocvlh   (other, 0.04605967924)     (FR, 0.0374619215727)   \n",
       "0048rkdgb1     (ES, 0.129884615541)     (US, 0.0932128354907)   \n",
       "0057snrdpu     (US, 0.135746642947)  (other, 0.0371996089816)   \n",
       "\n",
       "                                    4  \n",
       "0010k6l0om      (ES, 0.0103762643412)  \n",
       "0031awlkjq      (FR, 0.0223994627595)  \n",
       "00378ocvlh      (IT, 0.0294449161738)  \n",
       "0048rkdgb1  (other, 0.00932735390961)  \n",
       "0057snrdpu      (DE, 0.0197173804045)  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "some_other_df = pd.DataFrame(result).T\n",
    "some_other_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pd.DataFrame(some_other_df.unstack(0))\\\n",
    ".reset_index()\\\n",
    ".sort_values(['level_1','level_0'])[['level_1',0]].to_csv('something.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### This returns a score of 84.53% accuracy on the website"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
